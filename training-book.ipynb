{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9310fdd4",
   "metadata": {},
   "source": [
    "# Detector general de cascos (Helmet / No-helmet) — Notebook listo para Colab\n",
    "\n",
    "Este notebook:\n",
    "- Instala Ultralytics (YOLOv8) y herramientas útiles.\n",
    "- Intenta descargar un dataset público (Hugging Face). Si falla, te permite subir tu dataset en formato YOLO o COCO.\n",
    "- Convierte datos si es necesario, crea `data.yaml`.\n",
    "- Entrena un modelo `yolov8n` (rápido).\n",
    "- Ejecuta inferencia en imagen y vídeo (o webcam).\n",
    "- Exporta modelo para despliegue (ONNX opcional).\n",
    "\n",
    "Ejecuta celdas en orden. Usa GPU para entrenamiento (Colab: *Runtime > Change runtime type > GPU*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c502ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependencias (ejecutar en Colab)\n",
    "!pip install -q ultralytics datasets pycocotools fiftyone[desktop] roboflow --quiet\n",
    "!pip install -q opencv-python-headless matplotlib tqdm seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, json, random, math, sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "import IPython.display as disp\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def show_image(path, figsize=(10,6)):\n",
    "    img = Image.open(path)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print('Entorno listo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57496f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intento descargar dataset de Hugging Face. Si falla, habrá fallback para subir ZIP.\n",
    "from datasets import load_dataset\n",
    "dataset_name = \"UniqueData/helmet_detection\"\n",
    "data_dir = Path(\"helmet_dataset\")\n",
    "auto_ok = False\n",
    "\n",
    "print(\"Intentando descargar dataset desde Hugging Face:\", dataset_name)\n",
    "try:\n",
    "    ds = load_dataset(dataset_name)\n",
    "    print(\"Dataset cargado. Splits:\", list(ds.keys()))\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    auto_ok = True\n",
    "except Exception as e:\n",
    "    print(\"No se pudo descargar automáticamente el dataset:\\n\", e)\n",
    "    print(\"FALLBACK: sube un ZIP con tu dataset en formato YOLO (images/labels) o COCO usando la celda de subida.\")\n",
    "    auto_ok = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a34c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si la descarga automática funcionó, crear estructura YOLO básica en ./helmet_dataset\n",
    "if 'ds' in globals() and ds is not None and auto_ok:\n",
    "    print('Preparando estructura YOLO en ./helmet_dataset ...')\n",
    "    if data_dir.exists():\n",
    "        shutil.rmtree(data_dir)\n",
    "    (data_dir/'images'/'train').mkdir(parents=True, exist_ok=True)\n",
    "    (data_dir/'images'/'val').mkdir(parents=True, exist_ok=True)\n",
    "    (data_dir/'labels'/'train').mkdir(parents=True, exist_ok=True)\n",
    "    (data_dir/'labels'/'val').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    split_names = list(ds.keys())\n",
    "    print('Splits detectados:', split_names)\n",
    "    def process_split(split, out_img_dir, out_label_dir, max_images=None):\n",
    "        n = 0\n",
    "        for i, item in enumerate(ds[split]):\n",
    "            try:\n",
    "                img = item.get('image')\n",
    "                if img is None:\n",
    "                    path = item.get('img_path') or item.get('image_path') or item.get('file_name')\n",
    "                    if path is None:\n",
    "                        continue\n",
    "                    img = Image.open(path)\n",
    "                elif hasattr(img, 'to_numpy'):\n",
    "                    img = Image.fromarray(img.to_numpy())\n",
    "            except Exception as e:\n",
    "                # saltar items problemáticos\n",
    "                continue\n",
    "\n",
    "            fname = f\"{split}_{i:04d}.jpg\"\n",
    "            img_path = out_img_dir / fname\n",
    "            img.save(img_path)\n",
    "\n",
    "            objs = item.get('objects') or item.get('annotations') or item.get('labels') or item.get('bboxes')\n",
    "            label_lines = []\n",
    "            if objs:\n",
    "                for obj in objs:\n",
    "                    bbox = None\n",
    "                    if isinstance(obj, dict):\n",
    "                        bbox = obj.get('bbox')\n",
    "                    elif isinstance(obj, (list, tuple)) and len(obj) == 4:\n",
    "                        bbox = obj\n",
    "                    if bbox and len(bbox) == 4:\n",
    "                        x_min, y_min, x_max, y_max = bbox\n",
    "                        w_img, h_img = img.size\n",
    "                        x_c = (x_min + x_max)/2.0 / w_img\n",
    "                        y_c = (y_min + y_max)/2.0 / h_img\n",
    "                        w = (x_max - x_min) / w_img\n",
    "                        h = (y_max - y_min) / h_img\n",
    "                        cls = 0\n",
    "                        label_lines.append(f\"{cls} {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\")\n",
    "            with open(out_label_dir / (fname.replace('.jpg', '.txt')), 'w') as f:\n",
    "                f.write('\\n'.join(label_lines))\n",
    "\n",
    "            n += 1\n",
    "            if max_images and n >= max_images:\n",
    "                break\n",
    "\n",
    "    if 'train' in ds:\n",
    "        process_split('train', data_dir/'images'/'train', data_dir/'labels'/'train', max_images=2000)\n",
    "    else:\n",
    "        first = split_names[0]\n",
    "        process_split(first, data_dir/'images'/'train', data_dir/'labels'/'train', max_images=2000)\n",
    "\n",
    "    yaml_text = f\"\"\"train: {str((data_dir/'images'/'train').resolve())}\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fallback: subir ZIP con dataset en formato YOLO (images/labels) o COCO\n",
    "try:\n",
    "    from google.colab import files\n",
    "    import zipfile\n",
    "    if not auto_ok:\n",
    "        print('Sube aquí un ZIP con tu dataset en formato YOLO (images/labels) o COCO.')\n",
    "        uploaded = files.upload()\n",
    "        if len(uploaded) == 0:\n",
    "            print('No se subió nada.')\n",
    "        else:\n",
    "            for name in uploaded:\n",
    "                print('Subido:', name)\n",
    "                if name.lower().endswith('.zip'):\n",
    "                    with zipfile.ZipFile(name, 'r') as z:\n",
    "                        z.extractall('uploaded_dataset')\n",
    "                    print('Descomprimido en ./uploaded_dataset')\n",
    "                    if Path('uploaded_dataset/images').exists() and Path('uploaded_dataset/labels').exists():\n",
    "                        if data_dir.exists():\n",
    "                            shutil.rmtree(data_dir)\n",
    "                        shutil.move('uploaded_dataset', str(data_dir))\n",
    "                        print('Dataset colocado en ./helmet_dataset')\n",
    "                        yaml_text = f\"\"\"train: {str((data_dir/'images'/'train').resolve())}\n",
    "val: {str((data_dir/'images'/'val').resolve())}\n",
    "nc: 1\n",
    "names: ['helmet']\n",
    "\"\"\"\n",
    "                        with open(data_dir/'data.yaml','w') as f:\n",
    "                            f.write(yaml_text)\n",
    "                        print('data.yaml creado en ./helmet_dataset/data.yaml')\n",
    "                    else:\n",
    "                        print('No se detectó estructura images/labels en el ZIP. Revisa tu ZIP o organiza a mano.')\n",
    "except Exception as e:\n",
    "    print('La celda de subida solo funciona en Colab. Si estás en local, crea/coloca el dataset en ./helmet_dataset con estructura YOLO.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f24adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (data_dir/'images').exists():\n",
    "    print('Contenido de helmet_dataset/images (algunos ejemplos):')\n",
    "    p = list((data_dir/'images').rglob('*.jpg'))[:10]\n",
    "    for x in p:\n",
    "        print('-', x)\n",
    "    if p:\n",
    "        show_image(str(p[0]))\n",
    "else:\n",
    "    print('No se detectó un dataset en ./helmet_dataset.')\n",
    "    print('Opciones:')\n",
    "    print('1) Ejecuta la celda de subida y sube un ZIP con la estructura images/labels.')\n",
    "    print('2) Sube manualmente imágenes y crea anotaciones YOLO (cada .txt por imagen).')\n",
    "    print('3) Crea un dataset sintético o usa otro dataset público.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10854e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento con YOLOv8 (yolov8n). Ajusta epochs / batch si hace falta.\n",
    "data_yaml = data_dir/'data.yaml'\n",
    "if not data_yaml.exists():\n",
    "    print('No existe data.yaml en', data_dir, '\\nAsegúrate de crear/colocar tu dataset en formato YOLO y crear data.yaml.')\n",
    "else:\n",
    "    print('Iniciando entrenamiento con YOLOv8 (yolov8n). Revisa que el runtime tenga GPU.')\n",
    "    model = YOLO('yolov8n.pt')\n",
    "    results = model.train(data=str(data_yaml), epochs=20, imgsz=640, batch=8, name='helmet_exp')\n",
    "    print('Entrenamiento finalizado. Resultados en runs/train/helmet_exp')\n",
    "    ckpt = Path('runs/train/helmet_exp/weights/best.pt')\n",
    "    if ckpt.exists():\n",
    "        print('Checkpoint guardado en:', ckpt)\n",
    "    else:\n",
    "        print('Carpeta de pesos:', list(Path('runs/train').glob('*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66b1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferencia en imagen de prueba (si no hay imágenes, sube una)\n",
    "ckpt = Path('runs/train/helmet_exp/weights/best.pt')\n",
    "if not ckpt.exists():\n",
    "    print('No encuentro checkpoint. Usando yolov8n.pt por defecto para demo.')\n",
    "    model = YOLO('yolov8n.pt')\n",
    "else:\n",
    "    model = YOLO(str(ckpt))\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    sample_imgs = list((data_dir/'images').rglob('*.jpg')) if (data_dir/'images').exists() else []\n",
    "    if len(sample_imgs) == 0:\n",
    "        print('No hay imágenes de prueba en el dataset. Sube una imagen para inferencia.')\n",
    "        uploaded = files.upload()\n",
    "        imgs = []\n",
    "        for fn in uploaded:\n",
    "            imgs.append(fn)\n",
    "    else:\n",
    "        imgs = [str(sample_imgs[0])]\n",
    "except Exception:\n",
    "    # en entorno local\n",
    "    sample_imgs = list((data_dir/'images').rglob('*.jpg')) if (data_dir/'images').exists() else []\n",
    "    imgs = [str(sample_imgs[0])] if sample_imgs else []\n",
    "\n",
    "if len(imgs) == 0:\n",
    "    print('No hay imágenes para inferencia. Sube o coloca alguna en ./helmet_dataset/images.')\n",
    "else:\n",
    "    print('Ejecutando inferencia en:', imgs)\n",
    "    preds = model.predict(source=imgs, save=True, imgsz=640)\n",
    "    print('Guardado resultado en runs/detect/')\n",
    "    out_dir = Path('runs/detect')\n",
    "    if out_dir.exists():\n",
    "        runs = sorted(out_dir.iterdir(), key=os.path.getmtime)\n",
    "        last = runs[-1]\n",
    "        res_images = list(last.glob('*.jpg'))\n",
    "        if res_images:\n",
    "            show_image(str(res_images[0]))\n",
    "        else:\n",
    "            print('No se encontraron imágenes con predicciones en', last)\n",
    "    else:\n",
    "        print('No se creó runs/detect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a72030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferencia en vídeo (sube un vídeo). Guarda salida en runs/detect/\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print('Sube un vídeo (o coloca la ruta local si ya lo subiste).')\n",
    "    uploaded = files.upload()\n",
    "    video_paths = []\n",
    "    for fn in uploaded:\n",
    "        video_paths.append(fn)\n",
    "    if len(video_paths) == 0:\n",
    "        print('No se subió vídeo. Termina aquí o sube un archivo y vuelve a ejecutar.')\n",
    "    else:\n",
    "        video_in = video_paths[0]\n",
    "        print('Procesando vídeo:', video_in)\n",
    "        res = model.predict(source=video_in, save=True, stream=False, imgsz=640)\n",
    "        print('Resultado guardado en runs/detect/ (revisa la carpeta para el .mp4)')\n",
    "except Exception as e:\n",
    "    print('La celda de vídeo funciona en Colab. Si estás en local, coloca el vídeo en la ruta y usa model.predict.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247b3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo de webcam (funciona en Jupyter local; en Colab puede no funcionar establemente)\n",
    "import cv2\n",
    "from IPython.display import display, Image as IPyImage, clear_output\n",
    "\n",
    "def webcam_demo(model, max_frames=200):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print('Imposible abrir webcam.')\n",
    "        return\n",
    "    frame_count = 0\n",
    "    while frame_count < max_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        results = model.predict(frame, imgsz=640, conf=0.35, verbose=False)\n",
    "        img_render = results[0].plot()\n",
    "        _, encoded = cv2.imencode('.jpg', img_render[:, :, ::-1])\n",
    "        display(IPyImage(data=encoded.tobytes()))\n",
    "        clear_output(wait=True)\n",
    "        frame_count += 1\n",
    "    cap.release()\n",
    "\n",
    "print('Webcam demo definido. Descomenta la llamada a webcam_demo(model) para ejecutarlo si tu entorno soporta webcam.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79fa2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar checkpoint a ONNX (útil para CPU / Raspberry)\n",
    "ckpt = Path('runs/train/helmet_exp/weights/best.pt')\n",
    "if ckpt.exists():\n",
    "    m = YOLO(str(ckpt))\n",
    "    print('Exportando a ONNX...')\n",
    "    m.export(format='onnx')\n",
    "    print('Export completado.')\n",
    "else:\n",
    "    print('No se encontró checkpoint para exportar. Entrena primero.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79ae001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar CSV de detecciones a partir de un vídeo (frame, timestamp, class, conf, bbox)\n",
    "import csv\n",
    "from datetime import timedelta\n",
    "import cv2\n",
    "\n",
    "def detections_to_csv(video_path, out_csv='detections_log.csv'):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 25\n",
    "    frame_idx = 0\n",
    "    rows = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        results = model.predict(frame, imgsz=640, conf=0.35, verbose=False)\n",
    "        for det in results[0].boxes.data.tolist() if getattr(results[0], 'boxes', None) is not None else []:\n",
    "            x1, y1, x2, y2, score, cls = det\n",
    "            t_seconds = frame_idx / fps\n",
    "            ts = str(timedelta(seconds=t_seconds))\n",
    "            rows.append([frame_idx, ts, int(cls), float(score), float(x1), float(y1), float(x2), float(y2)])\n",
    "        frame_idx += 1\n",
    "    cap.release()\n",
    "    with open(out_csv, 'w', newline='') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(['frame','timestamp','class','score','x1','y1','x2','y2'])\n",
    "        w.writerows(rows)\n",
    "    print('CSV generado:', out_csv)\n",
    "\n",
    "# Uso: detections_to_csv('video.mp4', 'helmet_detections.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feac62a",
   "metadata": {},
   "source": [
    "## Consejos para mejorar tu detector\n",
    "\n",
    "- **Aumenta dataset**: más imágenes y diversidad (ángulos, iluminación, tipos de casco).\n",
    "- **Augmentations**: usa aumentos (flip, hue, blur) para robustez.\n",
    "- **Finetune más epochs**: 50-100 epochs si tienes datos suficientes.\n",
    "- **Clases adicionales**: separa \"helmet\" vs \"no_helmet\" vs \"person\" o \"bike/moto\" para lógica más fina.\n",
    "- **Tracker**: integra StrongSORT/ByteTrack para contar infractores por individuo.\n",
    "- **Umbral de confianza**: ajustar `conf` en inferencia para reducir falsos positivos/negativos.\n",
    "\n",
    "¡Listo! Si quieres que genere una versión más pequeña (solo demo con imágenes sintéticas) o que incluya un dataset público concreto (Kaggle/GitHub) dime cuál y lo adapto."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
