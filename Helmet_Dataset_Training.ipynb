{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9e9eb791",
      "metadata": {
        "id": "9e9eb791"
      },
      "source": [
        "# Helmet dataset unification & meta-classifier (YOLOv8)\n",
        "\n",
        "Datasets used (original sources):\n",
        "- Hard-Hat Detection: https://www.kaggle.com/datasets/andrewmvd/hard-hat-detection/data\n",
        "- Hard-Hat Workers (Roboflow / YOLO exported): https://public.roboflow.com/object-detection/hard-hat-workers/\n",
        "- Motorcycle Helmet Use Dataset: https://data.mendeley.com/datasets/bmy35m25pw/1\n",
        "- HelmetWearingImageDataset: https://data.mendeley.com/datasets/tm72fkfxd5/3\n",
        "\n",
        "Notebook tasks:\n",
        "1. Attempt to download datasets (Kaggle / Roboflow / Mendeley) if possible, otherwise use local folders.\n",
        "2. Inspect local dataset folders and determine format.\n",
        "3. Convert formats where needed (VOC → YOLO) and sample small subsets for CPU training.\n",
        "4. Train small YOLOv8 models per dataset (or small classifier for classification-only datasets).\n",
        "5. Run per-dataset models on a shared validation set and collect outputs.\n",
        "6. Train a small meta-classifier (LogisticRegression) to predict master classes from per-model outputs.\n",
        "\n",
        "Run top-to-bottom. Edit PARAMETERS cell to change sample sizes or paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "906aec89",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "906aec89",
        "outputId": "f68e8424-7384-4bee-f582-4acf37320247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Workdir: workdir_helmet_unify\n"
          ]
        }
      ],
      "source": [
        "ROOT = '.'  # parent folder containing dataset folders\n",
        "DATA_FOLDERS = {\n",
        "    'hard_hat_detection': 'Hard-Hat-Detection',\n",
        "    'hard_hat_workers': 'Hard-Hat-Workers',\n",
        "    'helmet_wearing_dataset': 'Helmet-Wearing-Image-Dataset',\n",
        "    'motorcycle_helmet_use': 'Motorcycle-Helmet-Use-Dataset',\n",
        "}\n",
        "\n",
        "SAMPLE_DETECTION = 200  # images sampled for detection datasets\n",
        "SAMPLE_CLASS_PER_LABEL = 200  # per-class samples for classification datasets\n",
        "\n",
        "# YOLO / training options\n",
        "YOLO_EPOCHS = 5\n",
        "YOLO_BATCH = 8\n",
        "YOLO_MODEL = 'yolov8n.pt'\n",
        "\n",
        "WORKDIR = 'workdir_helmet_unify'\n",
        "import os\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "print('Workdir:', WORKDIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "527489d7",
      "metadata": {
        "id": "527489d7"
      },
      "source": [
        "## 1) Attempt programmatic downloads (optional)\n",
        "\n",
        "Notes:\n",
        "- **Kaggle**: Programmatically downloaded using the Kaggle API and credentials provided in the next cell. Requires `kaggle` CLI.\n",
        "- **Roboflow**: Programmatically downloaded using the Roboflow Python library and API key provided in the next cell.\n",
        "- **Mendeley**: Programmatically downloaded using `wget` from a direct URL provided in the next cell.\n",
        "- **Motorcycle Helmet Use**: Programmatically downloaded using `wget` from a direct URL provided in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aa2e1cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aa2e1cc",
        "outputId": "0709975d-fc8e-4f61-e5c1-c10eb4f9d803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading Hard-Hat Detection from Kaggle...\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        },
        {
          "ename": "PermissionError",
          "evalue": "[Errno 13] Permission denied: '/root/.kaggle'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m kaggle_key = \u001b[33m\"\u001b[39m\u001b[33m4ca740ab8ae13bc6e46eecc6c92bd066\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m kaggle_config_dir = os.environ[\u001b[33m'\u001b[39m\u001b[33mKAGGLE_CONFIG_DIR\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkaggle_config_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(kaggle_config_dir, \u001b[33m'\u001b[39m\u001b[33mkaggle.json\u001b[39m\u001b[33m'\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     19\u001b[39m     f.write(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33musername\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkaggle_username\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mkey\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkaggle_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:228\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
            "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: '/root/.kaggle'"
          ]
        }
      ],
      "source": [
        "import os, zipfile, subprocess, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "os.makedirs(\"datasets\", exist_ok=True)\n",
        "\n",
        "# --- Kaggle: Hard-Hat Detection ---\n",
        "kaggle_extract_path = \"datasets/kaggle_hard_hat_detection\"\n",
        "os.makedirs(kaggle_extract_path, exist_ok=True)\n",
        "print(\"Downloading Hard-Hat Detection from Kaggle...\")\n",
        "!pip install -q kaggle\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/root/.kaggle'\n",
        "\n",
        "# Use provided Kaggle credentials\n",
        "kaggle_username = \"jesusudlap\"\n",
        "kaggle_key = \"4ca740ab8ae13bc6e46eecc6c92bd069\"\n",
        "kaggle_config_dir = os.environ['KAGGLE_CONFIG_DIR']\n",
        "os.makedirs(kaggle_config_dir, exist_ok=True)\n",
        "with open(os.path.join(kaggle_config_dir, 'kaggle.json'), 'w') as f:\n",
        "    f.write(f'{{\"username\":\"{kaggle_username}\",\"key\":\"{kaggle_key}\"}}')\n",
        "os.chmod(os.path.join(kaggle_config_dir, 'kaggle.json'), 0o600)\n",
        "\n",
        "kaggle_zip_path = os.path.join(kaggle_extract_path, \"hard-hat-detection.zip\")\n",
        "!kaggle datasets download -d andrewmvd/hard-hat-detection -p {kaggle_extract_path}\n",
        "if os.path.exists(kaggle_zip_path):\n",
        "    try:\n",
        "        with zipfile.ZipFile(kaggle_zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(kaggle_extract_path)\n",
        "            print(f\"Successfully unzipped Kaggle dataset to {kaggle_extract_path}\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"Error: Downloaded Kaggle zip file is not a valid zip file at {kaggle_zip_path}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during Kaggle extraction: {e}\")\n",
        "else:\n",
        "    print(f\"Error: Kaggle zip file not found at {kaggle_zip_path}. Download may have failed.\")\n",
        "\n",
        "\n",
        "# --- Roboflow: Hard-Hat Workers ---\n",
        "print(\"Downloading Hard-Hat Workers from Roboflow...\")\n",
        "!pip install roboflow\n",
        "\n",
        "try:\n",
        "    from roboflow import Roboflow\n",
        "    ROBOFLOW_API_KEY = \"4n1r1hgpHwXxLsq2yrE6\" # Using roboflow key\n",
        "    rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "    project = rf.workspace(\"joseph-nelson\").project(\"hard-hat-workers\")\n",
        "    version = project.version(10)\n",
        "    dataset = version.download(\"yolov8\")\n",
        "\n",
        "    roboflow_extract_path_auto = Path(dataset.location)\n",
        "    print(f\"Roboflow dataset downloaded and extracted to: {roboflow_extract_path_auto}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during Roboflow download or extraction: {e}\")\n",
        "    roboflow_extract_path_auto = None # Indicate failure\n",
        "\n",
        "\n",
        "# --- Mendeley: Helmet Wearing Dataset ---\n",
        "mendeley_url = \"https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/tm72fkfxd5-3.zip\"\n",
        "mendeley_zip_path = \"datasets/helmet_wearing_dataset.zip\"\n",
        "mendeley_extract_path = \"datasets/helmet_wearing_dataset\"\n",
        "os.makedirs(mendeley_extract_path, exist_ok=True)\n",
        "print(f\"Downloading Mendeley Helmet Wearing Dataset from {mendeley_url}...\")\n",
        "!wget {mendeley_url} -O {mendeley_zip_path}\n",
        "\n",
        "if os.path.exists(mendeley_zip_path):\n",
        "    print(f\"Found {mendeley_zip_path}. Attempting to unzip...\")\n",
        "    try:\n",
        "        with zipfile.ZipFile(mendeley_zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(mendeley_extract_path)\n",
        "            print(f\"Successfully unzipped Mendeley dataset to {mendeley_extract_path}\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"Error: Downloaded Mendeley zip file is not a valid zip file at {mendeley_zip_path}. Please verify the file.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during Mendeley extraction: {e}\")\n",
        "else:\n",
        "    print(f\"Error: Mendeley zip file not found at {mendeley_zip_path}. Download may have failed.\")\n",
        "\n",
        "\n",
        "# --- Motorcycle Helmet Use Dataset ---\n",
        "motorcycle_url = \"https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/bmy35m25pw-1.zip\"\n",
        "motorcycle_zip_path = \"datasets/motorcycle_helmet_use.zip\"\n",
        "motorcycle_extract_path = \"datasets/motorcycle_helmet_use\"\n",
        "os.makedirs(motorcycle_extract_path, exist_ok=True)\n",
        "print(f\"Downloading Motorcycle Helmet Use Dataset from {motorcycle_url}...\")\n",
        "!wget {motorcycle_url} -O {motorcycle_zip_path}\n",
        "\n",
        "if os.path.exists(motorcycle_zip_path):\n",
        "    print(f\"Found {motorcycle_zip_path}. Attempting to unzip...\")\n",
        "    try:\n",
        "        with zipfile.ZipFile(motorcycle_zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(motorcycle_extract_path)\n",
        "            print(f\"Successfully unzipped Motorcycle Helmet Use dataset to {motorcycle_extract_path}\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"Error: Motorcycle Helmet Use zip file is not a valid zip file at {motorcycle_zip_path}. Please verify the file.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during Motorcycle Helmet Use extraction: {e}\")\n",
        "else:\n",
        "    print(f\"Error: Motorcycle Helmet Use zip file not found at {motorcycle_zip_path}. Download may have failed.\")\n",
        "\n",
        "\n",
        "DATA_FOLDERS = {\n",
        "    'hard_hat_detection': kaggle_extract_path,\n",
        "    'hard_hat_workers': str(roboflow_extract_path_auto) if roboflow_extract_path_auto and roboflow_extract_path_auto.exists() else 'datasets/hard-hat-workers-10', # Use Roboflow auto path if successful, else use expected manual path\n",
        "    'helmet_wearing_dataset': mendeley_extract_path,\n",
        "    'motorcycle_helmet_use': motorcycle_extract_path,\n",
        "}\n",
        "\n",
        "print('\\nDataset download and extraction attempts complete. Please ensure all desired datasets are present in the specified DATA_FOLDERS paths.')\n",
        "print('Current DATA_FOLDERS mapping:', DATA_FOLDERS)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b155c44b",
      "metadata": {
        "id": "b155c44b"
      },
      "source": [
        "## 2) Inspect local folders and report format evidence\n",
        "This cell enumerates each dataset folder you specified and attempts to detect annotation formats (VOC XML, YOLO txt, or folder-classification).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e7f3ae5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e7f3ae5",
        "outputId": "98ffeb15-fd6a-4d20-9403-d56581effccd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"hard_hat_detection\": {\n",
            "    \"exists\": true,\n",
            "    \"n_imgs\": 5000,\n",
            "    \"n_xml\": 5000,\n",
            "    \"n_txt\": 0,\n",
            "    \"class_folders_sample\": [\n",
            "      [\n",
            "        \"images\",\n",
            "        5000\n",
            "      ]\n",
            "    ],\n",
            "    \"format\": \"pascal_voc\"\n",
            "  },\n",
            "  \"hard_hat_workers\": {\n",
            "    \"exists\": true,\n",
            "    \"n_imgs\": 7035,\n",
            "    \"n_xml\": 0,\n",
            "    \"n_txt\": 7037,\n",
            "    \"class_folders_sample\": [],\n",
            "    \"format\": \"yolo_txt\"\n",
            "  },\n",
            "  \"helmet_wearing_dataset\": {\n",
            "    \"exists\": true,\n",
            "    \"n_imgs\": 0,\n",
            "    \"n_xml\": 0,\n",
            "    \"n_txt\": 0,\n",
            "    \"class_folders_sample\": [],\n",
            "    \"format\": \"unknown\"\n",
            "  },\n",
            "  \"motorcycle_helmet_use\": {\n",
            "    \"exists\": true,\n",
            "    \"n_imgs\": 0,\n",
            "    \"n_xml\": 0,\n",
            "    \"n_txt\": 0,\n",
            "    \"class_folders_sample\": [],\n",
            "    \"format\": \"unknown\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import os, glob, random, json\n",
        "def detect_format(folder):\n",
        "    if not os.path.exists(folder):\n",
        "        return {'exists': False}\n",
        "    files = os.listdir(folder)\n",
        "    res = {'exists': True}\n",
        "    # check for xml annotations\n",
        "    xmls = glob.glob(os.path.join(folder, '**', '*.xml'), recursive=True)\n",
        "    txts = glob.glob(os.path.join(folder, '**', '*.txt'), recursive=True)\n",
        "    imgs = glob.glob(os.path.join(folder, '**', '*.jpg'), recursive=True) + glob.glob(os.path.join(folder, '**', '*.png'), recursive=True)\n",
        "    res['n_imgs'] = len(imgs)\n",
        "    res['n_xml'] = len(xmls)\n",
        "    res['n_txt'] = len(txts)\n",
        "    # detect folder-per-class (classification) by checking for subdirectories with many images\n",
        "    subdirs = [d for d in glob.glob(os.path.join(folder, '*')) if os.path.isdir(d)]\n",
        "    class_like = []\n",
        "    for d in subdirs:\n",
        "        n = len(glob.glob(os.path.join(d, '*.jpg')))+len(glob.glob(os.path.join(d, '*.png')))\n",
        "        if n>5:\n",
        "            class_like.append((os.path.basename(d), n))\n",
        "    res['class_folders_sample'] = class_like[:10]\n",
        "    if res['n_xml']>0:\n",
        "        res['format'] = 'pascal_voc'\n",
        "    elif res['n_txt']>0 and any('/labels/' in p.replace('\\\\','/') or p.endswith('.txt') for p in txts):\n",
        "        res['format'] = 'yolo_txt'\n",
        "    elif len(class_like)>0:\n",
        "        res['format'] = 'folder_classification'\n",
        "    else:\n",
        "        res['format'] = 'unknown'\n",
        "    return res\n",
        "\n",
        "inventory = {}\n",
        "for k,rel in DATA_FOLDERS.items():\n",
        "    p = os.path.join(ROOT, rel)\n",
        "    inventory[k] = detect_format(p)\n",
        "\n",
        "print(json.dumps(inventory, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61ab9932",
      "metadata": {
        "id": "61ab9932"
      },
      "source": [
        "## 3) Conversion utilities\n",
        "VOC XML → YOLO txt converter (normalized bboxes). If your datasets are VOC, run the conversion to create YOLO-format `labels/` files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21d18a55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21d18a55",
        "outputId": "cf13c52f-3ba0-4b9d-f30e-0d2d9f598d36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converter defined\n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image\n",
        "def voc_to_yolo(xml_path, img_path, classes_map, out_txt_path):\n",
        "    \"\"\"\n",
        "    xml_path: VOC XML file path\n",
        "    img_path: corresponding image path (to read width/height)\n",
        "    classes_map: dict mapping VOC class name -> numeric class index (for YOLO)\n",
        "    out_txt_path: output .txt path to write YOLO labels\n",
        "    \"\"\"\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "    size = root.find('size')\n",
        "    if size is not None:\n",
        "        w = int(size.find('width').text)\n",
        "        h = int(size.find('height').text)\n",
        "    else:\n",
        "        # fallback: read image\n",
        "        with Image.open(img_path) as im:\n",
        "            w, h = im.size\n",
        "    lines = []\n",
        "    for obj in root.findall('object'):\n",
        "        cls = obj.find('name').text\n",
        "        if cls not in classes_map:\n",
        "            continue\n",
        "        cls_id = classes_map[cls]\n",
        "        bb = obj.find('bndbox')\n",
        "        xmin = float(bb.find('xmin').text)\n",
        "        ymin = float(bb.find('ymin').text)\n",
        "        xmax = float(bb.find('xmax').text)\n",
        "        ymax = float(bb.find('ymax').text)\n",
        "        x_center = (xmin + xmax) / 2.0 / w\n",
        "        y_center = (ymin + ymax) / 2.0 / h\n",
        "        bw = (xmax - xmin) / w\n",
        "        bh = (ymax - ymin) / h\n",
        "        lines.append(f\"{cls_id} {x_center:.6f} {y_center:.6f} {bw:.6f} {bh:.6f}\")\n",
        "    if lines:\n",
        "        os.makedirs(os.path.dirname(out_txt_path), exist_ok=True)\n",
        "        with open(out_txt_path, 'w') as f:\n",
        "            f.write('\\n'.join(lines))\n",
        "    return len(lines)\n",
        "\n",
        "print('Converter defined')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c698bf87",
      "metadata": {
        "id": "c698bf87"
      },
      "source": [
        "## 4) Prepare a small YOLOv8 dataset structure for each dataset\n",
        "We will create folders under `WORKDIR/<dataset_name>/yolov8/` with `train/`, `val/`, and `labels/` that YOLOv8 expects.\n",
        "The conversion and sampling behavior depends on detected format (VOC/XML → convert; YOLO txt → copy; folder-classification → convert to small classification dataset or optionally to detection by using weak boxes).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2908439a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2908439a",
        "outputId": "13eebb38-8195-4b53-fd5a-8695973f1c9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prepare_yolo_folder defined\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "import math\n",
        "\n",
        "def prepare_yolo_folder(src_folder, ds_key, format_hint, sample_limit=SAMPLE_DETECTION, classes_map=None, master_map=None):\n",
        "    \"\"\"Prepare a small sample YOLOv8 dataset structure.\n",
        "    - src_folder: path to dataset root\n",
        "    - format_hint: 'pascal_voc', 'yolo_txt', 'folder_classification'\n",
        "    - classes_map: map of original class names -> class indices (for detectors)\n",
        "    - master_map: map of original class names -> master class string (for meta label building later)\n",
        "    \"\"\"\n",
        "    out_root = Path(WORKDIR) / ds_key / 'yolov8'\n",
        "    imgs_out = out_root / 'images'\n",
        "    lbls_out = out_root / 'labels'\n",
        "    for p in [imgs_out/'train', imgs_out/'val', lbls_out/'train', lbls_out/'val']:\n",
        "        p.mkdir(parents=True, exist_ok=True)\n",
        "    # find images\n",
        "    img_paths = list(Path(src_folder).rglob('*.jpg')) + list(Path(src_folder).rglob('*.png'))\n",
        "    random.shuffle(img_paths)\n",
        "    selected = img_paths[:sample_limit]\n",
        "    ntrain = int(len(selected)*0.8)\n",
        "    train = selected[:ntrain]\n",
        "    val = selected[ntrain:]\n",
        "    # conversion per format\n",
        "    if format_hint == 'pascal_voc':\n",
        "        # find XML for each image\n",
        "        for split, arr in [('train', train), ('val', val)]:\n",
        "            for img in arr:\n",
        "                img_out = imgs_out/ split / img.name\n",
        "                shutil.copyfile(img, img_out)\n",
        "                xml_path = img.with_suffix('.xml')\n",
        "                txt_out = lbls_out / split / (img.stem + '.txt')\n",
        "                if xml_path.exists():\n",
        "                    voc_to_yolo(str(xml_path), str(img), classes_map, str(txt_out))\n",
        "    elif format_hint == 'yolo_txt':\n",
        "        for split, arr in [('train', train), ('val', val)]:\n",
        "            for img in arr:\n",
        "                img_out = imgs_out/ split / img.name\n",
        "                shutil.copyfile(img, img_out)\n",
        "                # try find label file\n",
        "                cand1 = img.with_suffix('.txt')\n",
        "                cand2 = Path(src_folder) / 'labels' / (img.stem + '.txt')\n",
        "                if cand1.exists():\n",
        "                    shutil.copyfile(cand1, lbls_out/ split/ cand1.name)\n",
        "                elif cand2.exists():\n",
        "                    shutil.copyfile(cand2, lbls_out/ split/ cand2.name)\n",
        "    elif format_hint == 'folder_classification':\n",
        "        # We will not attempt detection conversion automatically. Instead we create a small classification set\n",
        "        # by copying images into images/train/ class subfolders. For later, we can use a classification head or\n",
        "        # use a simple detector trained on heuristic full-image boxes labeled as the master class (weak supervision).\n",
        "        class_dirs = [d for d in Path(src_folder).iterdir() if d.is_dir()]\n",
        "        for c in class_dirs:\n",
        "            imgs = list(c.glob('*.jpg')) + list(c.glob('*.png'))\n",
        "            if not imgs:\n",
        "                continue\n",
        "            sel = imgs[:sample_limit]\n",
        "            # copy into train/val randomly\n",
        "            random.shuffle(sel)\n",
        "            ntr = int(len(sel)*0.8)\n",
        "            for img in sel[:ntr]:\n",
        "                shutil.copyfile(img, imgs_out/'train'/img.name)\n",
        "            for img in sel[ntr:]:\n",
        "                shutil.copyfile(img, imgs_out/'val'/img.name)\n",
        "    else:\n",
        "        print('Unknown format for', src_folder)\n",
        "    # produce a data.yaml for YOLOv8 (for detection datasets)\n",
        "    data_yaml = {\n",
        "        'path': str(out_root),\n",
        "        'train': 'images/train',\n",
        "        'val': 'images/val',\n",
        "        'names': [],\n",
        "    }\n",
        "    if classes_map is not None:\n",
        "        # assume classes_map is dict name->id, convert to names by index\n",
        "        names = [None]*(max(classes_map.values())+1)\n",
        "        for k,v in classes_map.items():\n",
        "            names[v]=k\n",
        "        data_yaml['names'] = names\n",
        "    with open(out_root/'data.yaml', 'w') as f:\n",
        "        import yaml\n",
        "        yaml.safe_dump(data_yaml, f)\n",
        "    return out_root\n",
        "\n",
        "print('prepare_yolo_folder defined')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39d458f7",
      "metadata": {
        "id": "39d458f7"
      },
      "source": [
        "## 5) Define the mapping from dataset labels to master classes\n",
        "Edit `LABEL_MAPPING` if you want different behavior. Keys correspond to dataset-level class names; values are master-class strings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12ee6198",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12ee6198",
        "outputId": "7558a63c-37a9-4ab7-a6ab-ec18ef9726fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mapping ready. Master classes: ['construction_helmet', 'motorcycle_helmet', 'bicycle_helmet', 'no_helmet']\n"
          ]
        }
      ],
      "source": [
        "# Example label mapping (customize as needed)\n",
        "LABEL_MAPPING = {\n",
        "    # Kaggle / Hard-Hat-detection classes\n",
        "    'Helmet': 'construction_helmet',\n",
        "    'helmet': 'construction_helmet',\n",
        "    'hard_hat': 'construction_helmet',\n",
        "    'person_with_helmet': 'construction_helmet',\n",
        "    # Motorcycle dataset\n",
        "    'With Helmet': 'motorcycle_helmet',\n",
        "    'WithHelmet': 'motorcycle_helmet',\n",
        "    'Without Helmet': 'no_helmet',\n",
        "    'WithoutHelmet': 'no_helmet',\n",
        "    # HelmetWearingImageDataset example classes\n",
        "    'Full-Face Helmet': 'bicycle_helmet',\n",
        "    'Open-Face Helmet': 'bicycle_helmet',\n",
        "    'Incorrect': 'no_helmet',\n",
        "}\n",
        "\n",
        "MASTER_CLASSES = ['construction_helmet','motorcycle_helmet','bicycle_helmet','no_helmet']\n",
        "print('Mapping ready. Master classes:', MASTER_CLASSES)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73975806",
      "metadata": {
        "id": "73975806"
      },
      "source": [
        "## 6) Prepare each dataset (conversion + sampling)\n",
        "This cell will use the previously detected format (from the inventory) and prepare a small YOLOv8-ready folder under `WORKDIR/<dataset_key>/yolov8`.\n",
        "If you have classification-only datasets, it will copy images into `images/train` and `images/val` for later classification training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc3a212f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc3a212f",
        "outputId": "008d18c1-cd7e-4755-e676-27d7ec893034"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hard_hat_detection format= pascal_voc exists= True\n",
            "Detected classes for hard_hat_detection (VOC): {'head': 0, 'helmet': 1, 'person': 2}\n",
            "hard_hat_workers format= yolo_txt exists= True\n",
            "Detected classes for hard_hat_workers (YOLO txt from data.yaml): {'head': 0, 'helmet': 1, 'person': 2}\n",
            "helmet_wearing_dataset format= unknown exists= True\n",
            "Skipping unknown format for helmet_wearing_dataset\n",
            "motorcycle_helmet_use format= unknown exists= True\n",
            "Skipping unknown format for motorcycle_helmet_use\n",
            "\n",
            "Prepared datasets:\n",
            "hard_hat_detection: workdir_helmet_unify/hard_hat_detection/yolov8\n",
            "hard_hat_workers: workdir_helmet_unify/hard_hat_workers/yolov8\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "prepared = {}\n",
        "for ds_key, rel in DATA_FOLDERS.items():\n",
        "    src = os.path.join(ROOT, rel)\n",
        "    info = detect_format(src)\n",
        "    print(ds_key, 'format=', info.get('format'), 'exists=', info.get('exists'))\n",
        "\n",
        "    if not info.get('exists'):\n",
        "        print(f\"Skipping {ds_key}: dataset folder not found at {src}\")\n",
        "        continue\n",
        "\n",
        "    # heuristic class map: for VOC we'll map any 'Helmet'/'helmet' to index 0\n",
        "    classes_map = None\n",
        "    if info.get('format') == 'pascal_voc':\n",
        "        # create simple mapping (you can expand this by parsing unique class names in XMLs)\n",
        "        # Attempt to read actual class names from XMLs to build a more accurate classes_map\n",
        "        all_xmls = glob.glob(os.path.join(src, '**', '*.xml'), recursive=True)\n",
        "        unique_classes = set()\n",
        "        for xml_path in all_xmls:\n",
        "            try:\n",
        "                tree = ET.parse(xml_path)\n",
        "                root = tree.getroot()\n",
        "                for obj in root.findall('object'):\n",
        "                    unique_classes.add(obj.find('name').text)\n",
        "            except Exception as e:\n",
        "                print(f\"Error parsing {xml_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "        classes_map = {cls_name: i for i, cls_name in enumerate(sorted(list(unique_classes)))}\n",
        "        print(f\"Detected classes for {ds_key} (VOC): {classes_map}\")\n",
        "\n",
        "        out = prepare_yolo_folder(src, ds_key, 'pascal_voc', sample_limit=SAMPLE_DETECTION, classes_map=classes_map)\n",
        "\n",
        "    elif info.get('format') == 'yolo_txt':\n",
        "        # For YOLO txt, we don't know names; we will assume numeric classes are present. Create a placeholder names list.\n",
        "        # If a data.yaml exists in the source, we can try to copy it or read class names from there.\n",
        "        data_yaml_src = Path(src) / 'data.yaml'\n",
        "        if data_yaml_src.exists():\n",
        "            try:\n",
        "                with open(data_yaml_src, 'r') as f:\n",
        "                    src_data_yaml = yaml.safe_load(f)\n",
        "                    if 'names' in src_data_yaml:\n",
        "                        classes_map = {name: i for i, name in enumerate(src_data_yaml['names'])}\n",
        "                        print(f\"Detected classes for {ds_key} (YOLO txt from data.yaml): {classes_map}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not read data.yaml from {src}: {e}\")\n",
        "                classes_map = None # Fallback to no classes_map if data.yaml is bad\n",
        "\n",
        "        out = prepare_yolo_folder(src, ds_key, 'yolo_txt', sample_limit=SAMPLE_DETECTION, classes_map=classes_map)\n",
        "\n",
        "    elif info.get('format') == 'folder_classification':\n",
        "        print(f\"{ds_key} is folder classification. Preparing for classification training.\")\n",
        "        out = prepare_yolo_folder(src, ds_key, 'folder_classification', sample_limit=SAMPLE_CLASS_PER_LABEL)\n",
        "\n",
        "    else:\n",
        "        print('Skipping unknown format for', ds_key)\n",
        "        continue\n",
        "\n",
        "    prepared[ds_key] = str(out)\n",
        "\n",
        "print('\\nPrepared datasets:')\n",
        "print(yaml.safe_dump(prepared))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c3c016a",
      "metadata": {
        "id": "7c3c016a"
      },
      "source": [
        "## 7) Install YOLOv8 (Ultralytics) and small training loop\n",
        "We train small `yolov8n` models (nano) for a few epochs. On CPU this will be slow but workable for the small sample sizes above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17a76909",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17a76909",
        "outputId": "874fb98e-96b6-4c41-cbde-169141187ed5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics version installed\n"
          ]
        }
      ],
      "source": [
        "!pip install -q ultralytics==8.0.0  # pin a YOLOv8-compatible version\n",
        "from ultralytics import YOLO\n",
        "print('Ultralytics version installed')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acfdfa57",
      "metadata": {
        "id": "acfdfa57"
      },
      "source": [
        "## 8) Train per-dataset models\n",
        "This cell loops over prepared detection-style datasets and trains a YOLOv8 model on each (tiny model, few epochs). It stores trained weights under `WORKDIR/<dataset_key>/yolov8/runs/detect/train/weights/best.pt`.\n",
        "\n",
        "If a dataset was folder-classification only, we'll train a small classifier temporarily using a PyTorch torchvision model (simpler and faster than training a detector on weak boxes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "063205d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "063205d9",
        "outputId": "d4c1741b-3a7e-4608-b0cf-d90617a207dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training YOLOv8 on hard_hat_detection\n",
            "Error: YOLO model file yolov8n.pt not found. Skipping training for hard_hat_detection.\n",
            "Training YOLOv8 on hard_hat_workers\n",
            "Error: YOLO model file yolov8n.pt not found. Skipping training for hard_hat_workers.\n",
            "\n",
            "Trained models summary:\n",
            "{'hard_hat_detection': {'type': 'detection', 'model_path': None}, 'hard_hat_workers': {'type': 'detection', 'model_path': None}}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['workdir_helmet_unify/trained_models.pkl']"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import time\n",
        "from pathlib import Path\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader, ImageFolder\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "import torch.serialization\n",
        "\n",
        "# Add safe globals for torch.load to fix UnpicklingError\n",
        "torch.serialization.add_safe_globals(['DetectionModel'])\n",
        "\n",
        "\n",
        "# Custom Dataset for folder classification (used if ImageFolder is not suitable)\n",
        "class FolderClassificationDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.image_files = list(self.img_dir.iterdir())\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_files[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        # For inference, we don't need a label\n",
        "        # In training, we would need labels derived from folder names\n",
        "        return image, str(img_path)\n",
        "\n",
        "\n",
        "trained_models = {}\n",
        "for ds_key, out in prepared.items():\n",
        "    outp = Path(out)\n",
        "    data_yaml = outp / 'data.yaml'\n",
        "\n",
        "    if (outp / 'images' / 'train').exists() and not data_yaml.exists():\n",
        "        print('Training simple classifier on', ds_key)\n",
        "        # Assume it's a folder classification dataset prepared earlier\n",
        "\n",
        "        # Define transforms\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        val_transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        # Use ImageFolder assuming structure images/train/class_name/img.jpg\n",
        "        train_dir = outp / 'images' / 'train'\n",
        "        val_dir = outp / 'images' / 'val' # Using val for simple training demo\n",
        "\n",
        "        if not train_dir.exists() or not any(train_dir.iterdir()):\n",
        "             print(f\"No training images found for classification dataset {ds_key}. Skipping training.\")\n",
        "             trained_models[ds_key] = {'type':'classification', 'model_path': None, 'class_names': []}\n",
        "             continue\n",
        "\n",
        "        try:\n",
        "            train_dataset = ImageFolder(train_dir, transform=train_transform)\n",
        "            val_dataset = ImageFolder(val_dir, transform=val_transform)\n",
        "            train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "            val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "            num_classes = len(train_dataset.classes)\n",
        "            if num_classes < 2:\n",
        "                 print(f\"Classification dataset {ds_key} has only one class ({train_dataset.classes[0]}). Skipping training.\")\n",
        "                 trained_models[ds_key] = {'type':'classification', 'model_path': None, 'class_names': train_dataset.classes}\n",
        "                 continue\n",
        "\n",
        "\n",
        "            # Simple model for demonstration\n",
        "            model = models.resnet18(weights=None) # Use weights=None to avoid downloading if preferred\n",
        "            num_ftrs = model.fc.in_features\n",
        "            model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            model.to(device)\n",
        "\n",
        "            print(f\"Starting classification training for {ds_key} on {device}...\")\n",
        "            # Basic training loop (tiny epochs for demo)\n",
        "            num_epochs = 5 # Keep small\n",
        "            for epoch in range(num_epochs):\n",
        "                model.train()\n",
        "                running_loss = 0.0\n",
        "                for inputs, labels in train_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                epoch_loss = running_loss / len(train_dataset)\n",
        "                print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "            # Save the trained model\n",
        "            model_save_path = Path(WORKDIR) / ds_key / 'classification_model.pth'\n",
        "            torch.save(model.state_dict(), model_save_path)\n",
        "            print(f\"Finished training {ds_key}. Model saved to {model_save_path}\")\n",
        "            trained_models[ds_key] = {'type':'classification', 'model_path': str(model_save_path), 'class_names': train_dataset.classes}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during classification training for {ds_key}: {e}\")\n",
        "            trained_models[ds_key] = {'type':'classification', 'model_path': None, 'class_names': []}\n",
        "\n",
        "\n",
        "    elif data_yaml.exists():\n",
        "        print('Training YOLOv8 on', ds_key)\n",
        "        # load model - YOLO constructor handles downloading .pt if not local\n",
        "        try:\n",
        "            model = YOLO(YOLO_MODEL)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading YOLO model {YOLO_MODEL}: {e}\")\n",
        "            trained_models[ds_key] = {'type':'detection', 'model_path': None}\n",
        "            continue\n",
        "\n",
        "        # training arguments - keep tiny for CPU/small sample\n",
        "        save_dir = str(Path(WORKDIR)/ds_key/'yolov8'/'runs'/'detect'/'train')\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        results = model.train(data=str(data_yaml), epochs=YOLO_EPOCHS, batch=YOLO_BATCH, imgsz=640, project=str(Path(WORKDIR)/ds_key/'yolov8'/'runs'/'detect'), name='train')\n",
        "        # store best weights path\n",
        "        best = list((Path(WORKDIR)/ds_key/'yolov8'/'runs'/'detect'/'train').rglob('best.pt'))\n",
        "        if best:\n",
        "            trained_models[ds_key] = {'type':'detection', 'model_path': str(best[0])}\n",
        "        else:\n",
        "            # fallback: take last.pt\n",
        "            last = list((Path(WORKDIR)/ds_key/'yolov8'/'runs'/'detect'/'train').rglob('last.pt'))\n",
        "            trained_models[ds_key] = {'type':'detection', 'model_path': str(last[0]) if last else None}\n",
        "    else:\n",
        "        print(f\"Skipping training for {ds_key}: neither data.yaml nor classification images/train folder found.\")\n",
        "\n",
        "    time.sleep(1)\n",
        "\n",
        "print('\\nTrained models summary:')\n",
        "print(trained_models)\n",
        "# save summary\n",
        "joblib.dump(trained_models, Path(WORKDIR)/'trained_models.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c28bd3bd",
      "metadata": {
        "id": "c28bd3bd"
      },
      "source": [
        "## 9) Run per-dataset models on a shared validation set and collect outputs\n",
        "We will create a small `meta_val` image set (from all prepared val folders) and run each per-dataset model to collect per-image per-class scores.\n",
        "For detection models, we map detection classes to master classes via `LABEL_MAPPING` and aggregate scores (e.g., max score for each master class). For classifiers, we will collect the softmax probability per master class if predicted.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c38b7773",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c38b7773",
        "outputId": "fcd1e4b3-71b1-4e56-88fa-e548ad000a65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Meta-val images: 317\n",
            "Feature matrix shape: (317, 8)\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "meta_images = []\n",
        "meta_dir = Path(WORKDIR)/'meta_val'\n",
        "meta_dir.mkdir(parents=True, exist_ok=True)\n",
        "for ds_key in prepared:\n",
        "    imgs_folder = Path(prepared[ds_key])/'images'/'val'\n",
        "    if not imgs_folder.exists():\n",
        "        continue\n",
        "    for imgp in imgs_folder.iterdir():\n",
        "        if imgp.suffix.lower() not in ['.jpg', '.png']:\n",
        "            continue\n",
        "        # copy to meta_val with unique name\n",
        "        dest = meta_dir / f\"{ds_key}__{imgp.name}\"\n",
        "        shutil.copyfile(imgp, dest)\n",
        "        meta_images.append(dest)\n",
        "print('Meta-val images:', len(meta_images))\n",
        "\n",
        "# Run models\n",
        "meta_features = []\n",
        "meta_filenames = []\n",
        "for imgp in meta_images:\n",
        "    filename = str(imgp)\n",
        "    feats = {}\n",
        "    for ds_key, info in trained_models.items():\n",
        "        if info['model_path'] is None:\n",
        "            # no model trained for this dataset\n",
        "            continue\n",
        "        if info['type']=='detection':\n",
        "            ymodel = YOLO(info['model_path'])\n",
        "            results = ymodel.predict(source=filename, conf=0.25, imgsz=640)\n",
        "            # aggregate scores per master class\n",
        "            agg = {mc:0.0 for mc in MASTER_CLASSES}\n",
        "            if len(results) > 0:\n",
        "                boxes = results[0].boxes\n",
        "                cls_ids = boxes.cls.numpy().astype(int) if hasattr(boxes, 'cls') else []\n",
        "                scores = boxes.conf.numpy() if hasattr(boxes, 'conf') else []\n",
        "                # attempt to map predicted numeric class to a name using the model's YAML names if available\n",
        "                try:\n",
        "                    names = results[0].names\n",
        "                except Exception:\n",
        "                    names = {}\n",
        "                for cid, sc in zip(cls_ids, scores):\n",
        "                    name = names.get(cid, str(cid))\n",
        "                    master = LABEL_MAPPING.get(name, None)\n",
        "                    if master is None:\n",
        "                        # heuristic: if name contains 'helmet' map to construction_helmet\n",
        "                        if 'helmet' in name.lower():\n",
        "                            master = 'construction_helmet'\n",
        "                        else:\n",
        "                            master = 'no_helmet'\n",
        "                    agg[master] = max(agg[master], float(sc))\n",
        "            feats.update({f'{ds_key}__{mc}': agg[mc] for mc in MASTER_CLASSES})\n",
        "        else:\n",
        "            # classification stub (not implemented fully earlier). Put zeros for features for now.\n",
        "            feats.update({f'{ds_key}__{mc}': 0.0 for mc in MASTER_CLASSES})\n",
        "    meta_features.append([feats.get(f'{ds_key}__{mc}',0.0) for ds_key in prepared for mc in MASTER_CLASSES])\n",
        "    meta_filenames.append(filename)\n",
        "\n",
        "X = np.array(meta_features)\n",
        "print('Feature matrix shape:', X.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "600377ea",
      "metadata": {
        "id": "600377ea"
      },
      "source": [
        "## 10) Build labels for meta-classifier\n",
        "If you have ground-truth labels per image for this meta-val set, load them here. Otherwise, this notebook will create *pseudo-labels* by applying simple heuristics from folder names.\n",
        "For proper performance, supply true labels or create a curated validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98a08fae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98a08fae",
        "outputId": "2657f1c0-373d-4bd7-ff96-c32782fc6fd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label distribution (heuristic): {'construction_helmet': 317, 'motorcycle_helmet': 0, 'bicycle_helmet': 0, 'no_helmet': 0}\n"
          ]
        }
      ],
      "source": [
        "# Heuristic label assignment: if filename contains known master class keyword, assign it\n",
        "y = []\n",
        "for fn in meta_filenames:\n",
        "    lname = 'no_helmet' # Default to no_helmet if no specific keyword is found\n",
        "    low = fn.lower()\n",
        "    if 'motor' in low or 'motorcycle' in low:\n",
        "        lname = 'motorcycle_helmet'\n",
        "    elif 'hard' in low or 'hat' in low or 'construction' in low:\n",
        "        lname = 'construction_helmet'\n",
        "    elif 'bicycle' in low or 'bike' in low:\n",
        "        lname = 'bicycle_helmet'\n",
        "    elif 'without' in low or 'nohelmet' in low or 'incorrect' in low:\n",
        "         lname = 'no_helmet' # Explicitly assign no_helmet if these keywords are present\n",
        "    # If filename doesn't contain any of the specific keywords, it remains 'no_helmet'\n",
        "    y.append(MASTER_CLASSES.index(lname))\n",
        "import numpy as np\n",
        "y = np.array(y)\n",
        "print('Label distribution (heuristic):', {MASTER_CLASSES[i]:int((y==i).sum()) for i in range(len(MASTER_CLASSES))})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c472179",
      "metadata": {
        "id": "7c472179"
      },
      "source": [
        "## 11) Train meta-classifier (LogisticRegression)\n",
        "We train a tiny logistic regression on the meta features to predict the master classes. In practice, use a curated labeled meta training set.\n",
        "\n",
        "*(Skipped in this version, using fuzzy logic instead)*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c22bedcd",
      "metadata": {
        "id": "c22bedcd"
      },
      "source": [
        "## 12) Inference: full pipeline example\n",
        "Given a new image, run each trained dataset model, collect scores, and predict master class via the meta-classifier. Example code below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94ad69b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94ad69b4",
        "outputId": "d66bf424-4915-43fc-cd07-39938e99f490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fuzzy pipeline predict function defined (requires loaded trained_models)\n"
          ]
        }
      ],
      "source": [
        "def predict_master_fuzzy(image_path, trained_models):\n",
        "    feats = {}\n",
        "    for ds_key, info in trained_models.items():\n",
        "        # Initialize features for all master classes for this dataset\n",
        "        for mc in MASTER_CLASSES:\n",
        "             feats[f'{ds_key}__{mc}'] = 0.0\n",
        "\n",
        "        if info['model_path'] is None:\n",
        "            # no model trained for this dataset, features remain 0.0\n",
        "            continue\n",
        "\n",
        "        if info['type']=='detection':\n",
        "            # Load the model with safe globals if needed (already added in training cell)\n",
        "            try:\n",
        "                 ymodel = YOLO(info['model_path'])\n",
        "            except Exception as e:\n",
        "                 print(f\"Error loading model {info['model_path']}: {e}\")\n",
        "                 continue # Skip this model if loading fails\n",
        "\n",
        "            results = ymodel.predict(source=image_path, conf=0.25, imgsz=640, verbose=False) # verbose=False to reduce output\n",
        "            # aggregate scores per master class\n",
        "            agg = {mc:0.0 for mc in MASTER_CLASSES}\n",
        "            if len(results) > 0 and results[0] is not None:\n",
        "                boxes = results[0].boxes\n",
        "                if boxes is not None: # Check if boxes exist\n",
        "                    cls_ids = boxes.cls.numpy().astype(int) if hasattr(boxes, 'cls') and boxes.cls is not None else []\n",
        "                    scores = boxes.conf.numpy() if hasattr(boxes, 'conf') and boxes.conf is not None else []\n",
        "                    # attempt to map predicted numeric class to a name using the model's YAML names if available\n",
        "                    try:\n",
        "                        names = results[0].names\n",
        "                    except Exception:\n",
        "                        names = {}\n",
        "                    for cid, sc in zip(cls_ids, scores):\n",
        "                        name = names.get(cid, str(cid))\n",
        "                        master = LABEL_MAPPING.get(name, None)\n",
        "                        if master is None:\n",
        "                            # heuristic: if name contains 'helmet' map to construction_helmet\n",
        "                            if 'helmet' in name.lower():\n",
        "                                master = 'construction_helmet'\n",
        "                            else:\n",
        "                                master = 'no_helmet' # Default to no_helmet if no mapping or heuristic match\n",
        "                        agg[master] = max(agg[master], float(sc)) # Take max score per master class\n",
        "\n",
        "            # Update feats with aggregated scores from this model\n",
        "            for mc in MASTER_CLASSES:\n",
        "                 feats[f'{ds_key}__{mc}'] = agg[mc]\n",
        "\n",
        "        # Add handling for classification models if implemented later\n",
        "        elif info['type']=='classification':\n",
        "             print(f\"Classification model inference not fully implemented for {ds_key}\")\n",
        "             # Placeholder for classification model inference\n",
        "\n",
        "    # --- Fuzzy Prediction Logic ---\n",
        "    # Aggregate scores across all models for each master class\n",
        "    master_class_scores = {mc: 0.0 for mc in MASTER_CLASSES}\n",
        "    for mc in MASTER_CLASSES:\n",
        "        # Sum or average scores from different models for the same master class\n",
        "        # Using max score across models for simplicity in this fuzzy example\n",
        "        master_class_scores[mc] = max(feats.get(f'{ds_key}__{mc}', 0.0) for ds_key in trained_models)\n",
        "\n",
        "    # Find the master class with the highest score\n",
        "    predicted_master_class = 'no_helmet' # Default prediction\n",
        "    max_score = 0.0\n",
        "    # You could add a threshold here, e.g., if max_score < threshold, predict 'unknown' or 'no_helmet'\n",
        "    for mc, score in master_class_scores.items():\n",
        "        if score > max_score: # or if score > threshold and score > max_score\n",
        "            max_score = score\n",
        "            predicted_master_class = mc\n",
        "\n",
        "    return predicted_master_class, master_class_scores\n",
        "\n",
        "print('Fuzzy pipeline predict function defined (requires loaded trained_models)')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f961a1d",
      "metadata": {
        "id": "9f961a1d"
      },
      "source": [
        "## 13) Test the Fuzzy Inference Pipeline\n",
        "\n",
        "This cell demonstrates how to use the `predict_master_fuzzy` function on the images in the `meta_val` folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccb92592",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccb92592",
        "outputId": "21829b79-4a42-4f38-c6b4-c3db4c44c4cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing fuzzy inference on 317 meta-validation images...\n",
            "\n",
            "Sample Test Results:\n",
            "Image: hard_hat_workers__006217_jpg.rf.97b675ef7f9d8a93e58c465c69fcb85b.jpg, Predicted Class: no_helmet, Scores: {'construction_helmet': 0.0, 'motorcycle_helmet': 0.0, 'bicycle_helmet': 0.0, 'no_helmet': 0.0}\n",
            "Image: hard_hat_detection__hard_hat_workers151.png, Predicted Class: no_helmet, Scores: {'construction_helmet': 0.0, 'motorcycle_helmet': 0.0, 'bicycle_helmet': 0.0, 'no_helmet': 0.0}\n",
            "Image: hard_hat_workers__000718_jpg.rf.c718130bb1f8b6fdcbeb2592398f01dc.jpg, Predicted Class: no_helmet, Scores: {'construction_helmet': 0.0, 'motorcycle_helmet': 0.0, 'bicycle_helmet': 0.0, 'no_helmet': 0.0}\n",
            "Image: hard_hat_detection__hard_hat_workers1123.png, Predicted Class: no_helmet, Scores: {'construction_helmet': 0.0, 'motorcycle_helmet': 0.0, 'bicycle_helmet': 0.0, 'no_helmet': 0.0}\n",
            "Image: hard_hat_workers__001708_jpg.rf.185841b26a89e71b0f7b40b9c3825b5c.jpg, Predicted Class: no_helmet, Scores: {'construction_helmet': 0.0, 'motorcycle_helmet': 0.0, 'bicycle_helmet': 0.0, 'no_helmet': 0.0}\n",
            "Image: hard_hat_detection__hard_hat_workers4070.png, Predicted Class: no_helmet, Scores: {'construction_helmet': 0.0, 'motorcycle_helmet': 0.0, 'bicycle_helmet': 0.0, 'no_helmet': 0.0}\n",
            "Image: hard_hat_workers__002831_jpg.rf.85008d68b89df142aa3b7a61df5b4811.jpg, Predicted Class: no_helmet, Scores: {'construction_helmet': 0.0, 'motorcycle_helmet': 0.0, 'bicycle_helmet': 0.0, 'no_helmet': 0.0}\n",
            "Image: hard_hat_workers__005584_jpg.rf.ee5eacfdccc3a0e6627fefdb54979212.jpg, Predicted Class: no_helmet, Scores: {'construction_helmet': 0.0, 'motorcycle_helmet': 0.0, 'bicycle_helmet': 0.0, 'no_helmet': 0.0}\n",
            "Image: hard_hat_workers__002422_jpg.rf.f63d95d1c2c30101cea3fd2220920c28.jpg, Predicted Class: no_helmet, Scores: {'construction_helmet': 0.0, 'motorcycle_helmet': 0.0, 'bicycle_helmet': 0.0, 'no_helmet': 0.0}\n",
            "Image: hard_hat_workers__003612_jpg.rf.ddd179763b850483edfc17c8d570f289.jpg, Predicted Class: no_helmet, Scores: {'construction_helmet': 0.0, 'motorcycle_helmet': 0.0, 'bicycle_helmet': 0.0, 'no_helmet': 0.0}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "# Ensure trained_models is loaded if the kernel restarted\n",
        "if 'trained_models' not in locals() and Path(WORKDIR)/'trained_models.pkl'.exists():\n",
        "    import joblib\n",
        "    trained_models = joblib.load(Path(WORKDIR)/'trained_models.pkl')\n",
        "    print(\"Loaded trained_models from file.\")\n",
        "elif 'trained_models' not in locals():\n",
        "    print(\"Error: trained_models not found. Please run training cells first.\")\n",
        "\n",
        "\n",
        "meta_dir = Path(WORKDIR)/'meta_val'\n",
        "meta_images_for_test = list(meta_dir.iterdir())\n",
        "\n",
        "print(f\"Testing fuzzy inference on {len(meta_images_for_test)} meta-validation images...\")\n",
        "\n",
        "test_results = []\n",
        "for img_path in meta_images_for_test:\n",
        "    if img_path.suffix.lower() not in ['.jpg', '.png']:\n",
        "        continue\n",
        "    predicted_class, scores = predict_master_fuzzy(str(img_path), trained_models)\n",
        "    test_results.append({'image': img_path.name, 'predicted_master_class': predicted_class, 'scores': scores})\n",
        "\n",
        "# Display a few results\n",
        "print(\"\\nSample Test Results:\")\n",
        "for i, result in enumerate(test_results[:10]):\n",
        "    print(f\"Image: {result['image']}, Predicted Class: {result['predicted_master_class']}, Scores: {result['scores']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37081de1",
      "metadata": {
        "id": "37081de1"
      },
      "source": [
        "## Final notes & next steps\n",
        "- If you plan to run this on Colab with a GPU: set `YOLO_MODEL='yolov8s.pt'`, increase `SAMPLE_*` and `YOLO_EPOCHS`, and enable GPU runtime.\n",
        "- For best meta-classifier performance, curate a labeled set of images with ground-truth master classes (not heuristic labels) and retrain the meta-classifier.\n",
        "- If you want me to produce a version of this notebook that *automatically downloads* and fully prepares each dataset (including parsing dataset-specific class names and building exact `classes_map`), tell me which datasets you want downloaded automatically and provide credentials (Kaggle API token, Roboflow API key). I can then update download code with exact dataset slugs/URLs.\n",
        "\n",
        "If anything should be changed in the mapping or sample sizes before I finalize a variant for Colab usage, tell me and I will adjust the notebook accordingly."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.13.7)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
