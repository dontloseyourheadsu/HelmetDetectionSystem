{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sterile Field Detector: Comparative Experimentation\n",
    "\n",
    "This notebook modifies the original Sterile Field Detector pipeline to benchmark different model configurations and preprocessing techniques. \n",
    "\n",
    "**Objective:** Compare the \"Current Best\" (Top-Hat Preprocessing + CNN/AE) against other variations (Raw Data, Generic Filtering) to validate the architectural decisions.\n",
    "\n",
    "**Experiments:**\n",
    "1. **Baseline:** Original Morphological Top-Hat Transform.\n",
    "2. **No Filter:** Raw video frames (to test robustness without preprocessing).\n",
    "3. **Gaussian Blur:** Generic noise reduction (to test if specific texture extraction is necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Setup & Dependencies ---\n",
    "!pip install inference-sdk python-dotenv\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import cv2\n",
    "import gdown\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, recall_score, precision_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Dataset Download & Extraction ---\n",
    "DATASET_LINK = \"https://drive.google.com/drive/folders/1gLRc8noJhQjpkD0F6hnvUO92qi5YrbXH?usp=drive_link\"\n",
    "ROOT = pathlib.Path(\".\").resolve()\n",
    "DOWNLOAD_DIR = ROOT / \"dataset\" / \"download\"\n",
    "FRAMES_DIR = ROOT / \"dataset\" / \"frames\"\n",
    "VIDEO_EXTS = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".webm\"}\n",
    "\n",
    "def download_dataset():\n",
    "    DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    if list(DOWNLOAD_DIR.glob(\"*\")):\n",
    "        print(\"Dataset already downloaded.\")\n",
    "        return\n",
    "    print(\"Downloading dataset...\")\n",
    "    try:\n",
    "        gdown.download_folder(DATASET_LINK, output=str(DOWNLOAD_DIR), quiet=False)\n",
    "    except:\n",
    "        # Fallback or manual download message if gdown fails on folder\n",
    "        print(\"Please ensure the dataset videos are in\", DOWNLOAD_DIR)\n",
    "\n",
    "def extract_frames(video_path, target_count=500):\n",
    "    # Extract frames from video\n",
    "    class_name = video_path.stem.split(' ')[0].lower() # Assumes format like 'Clean.mp4' or 'Trash.mp4'\n",
    "    out_dir = FRAMES_DIR / class_name\n",
    "    if out_dir.exists(): return # Skip if done\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    indices = np.linspace(0, total_frames-1, target_count, dtype=int)\n",
    "    \n",
    "    count = 0\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            cv2.imwrite(str(out_dir / f\"frame_{count:04d}.jpg\"), frame)\n",
    "            count += 1\n",
    "    cap.release()\n",
    "\n",
    "download_dataset()\n",
    "videos = list(DOWNLOAD_DIR.glob(\"*.mp4\"))\n",
    "for v in videos: \n",
    "    extract_frames(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Define Preprocessing Variations ---\n",
    "# We define multiple filter functions to test different hypotheses\n",
    "\n",
    "def filter_baseline_tophat(image):\n",
    "    \"\"\"The original 'Best' method: TopHat + Contrast Enhancement\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Bilateral filter to remove noise while keeping edges\n",
    "    smoothed = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "    \n",
    "    # TopHat to highlight small light objects (crumbs)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (19, 19))\n",
    "    white_tophat = cv2.morphologyEx(smoothed, cv2.MORPH_TOPHAT, kernel)\n",
    "    \n",
    "    # BlackHat to highlight small dark objects (hair)\n",
    "    black_tophat = cv2.morphologyEx(smoothed, cv2.MORPH_BLACKHAT, kernel)\n",
    "    \n",
    "    # Combine: Base + CrumbBoost - HairBoost\n",
    "    result = smoothed.astype(np.float32) + (white_tophat * 2.0) - (black_tophat * 2.0)\n",
    "    result = np.clip(result, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # CLAHE for final contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    return clahe.apply(result)\n",
    "\n",
    "def filter_none(image):\n",
    "    \"\"\"Control group: Raw grayscale conversion only\"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def filter_gaussian(image):\n",
    "    \"\"\"Generic noise reduction: Simple Gaussian Blur\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.GaussianBlur(gray, (5, 5), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Model Definitions ---\n",
    "# We define factories for the models so we can instantiate fresh ones for each experiment\n",
    "\n",
    "IMG_SIZE = (128, 128)\n",
    "\n",
    "def build_cnn_classifier(num_classes=3):\n",
    "    \"\"\"Standard VGG-style CNN for classification\"\"\"\n",
    "    model = models.Sequential([\n",
    "        Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 1)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_autoencoder():\n",
    "    \"\"\"Unsupervised Anomaly Detector\"\"\"\n",
    "    input_img = Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 1))\n",
    "    \n",
    "    # Encoder\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same', strides=2)(input_img)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides=2)(x)\n",
    "    encoded = layers.Conv2D(128, (3, 3), activation='relu', padding='same', strides=2)(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same', strides=2)(encoded)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same', strides=2)(x)\n",
    "    decoded = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same', strides=2)(x)\n",
    "    \n",
    "    autoencoder = models.Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Experiment Logic ---\n",
    "\n",
    "def load_data_with_filter(filter_func):\n",
    "    \"\"\"Loads and processes data on the fly\"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    classes = sorted([d.name for d in FRAMES_DIR.iterdir() if d.is_dir()])\n",
    "    class_map = {name: i for i, name in enumerate(classes)}\n",
    "    \n",
    "    # We limit to a subset to speed up experimentation\n",
    "    for cls in classes:\n",
    "        files = list((FRAMES_DIR / cls).glob(\"*.jpg\"))[:300] \n",
    "        for f in files:\n",
    "            img = cv2.imread(str(f))\n",
    "            processed = filter_func(img)\n",
    "            processed = cv2.resize(processed, IMG_SIZE)\n",
    "            \n",
    "            # Normalize to 0-1\n",
    "            processed = processed.astype('float32') / 255.0\n",
    "            processed = np.expand_dims(processed, axis=-1)\n",
    "            \n",
    "            X.append(processed)\n",
    "            y.append(class_map[cls])\n",
    "            \n",
    "    return np.array(X), np.array(y), classes\n",
    "\n",
    "def run_experiment(name, filter_func):\n",
    "    print(f\"\\n--- Running Experiment: {name} ---\")\n",
    "    \n",
    "    # 1. Prepare Data\n",
    "    X, y, classes = load_data_with_filter(filter_func)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # One-hot encode for CNN\n",
    "    y_train_cat = to_categorical(y_train, num_classes=len(classes))\n",
    "    y_test_cat = to_categorical(y_test, num_classes=len(classes))\n",
    "    \n",
    "    # 2. Train CNN\n",
    "    print(f\"Training CNN ({name})...\")\n",
    "    cnn = build_cnn_classifier(len(classes))\n",
    "    history_cnn = cnn.fit(X_train, y_train_cat, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "    cnn_loss, cnn_acc = cnn.evaluate(X_test, y_test_cat, verbose=0)\n",
    "    \n",
    "    # 3. Train Autoencoder (Anomaly Detection)\n",
    "    # AE trains ONLY on 'clean' class (index 0 usually, assuming alphabetical)\n",
    "    clean_idx = [i for i, c in enumerate(classes) if 'clean' in c.lower()][0]\n",
    "    X_clean_train = X_train[y_train == clean_idx]\n",
    "    \n",
    "    print(f\"Training Autoencoder ({name})...\")\n",
    "    ae = build_autoencoder()\n",
    "    ae.fit(X_clean_train, X_clean_train, epochs=10, batch_size=32, shuffle=True, verbose=0)\n",
    "    \n",
    "    # Evaluate AE: Calculate reconstruction error on Test set\n",
    "    reconstructions = ae.predict(X_test, verbose=0)\n",
    "    mse = np.mean(np.power(X_test - reconstructions, 2), axis=(1, 2, 3))\n",
    "    \n",
    "    # Simple anomaly classification: If error > threshold -> Anomaly\n",
    "    # We determine threshold dynamically based on clean test data\n",
    "    clean_test_mask = (y_test == clean_idx)\n",
    "    threshold = np.mean(mse[clean_test_mask]) + 2 * np.std(mse[clean_test_mask])\n",
    "    \n",
    "    y_pred_anomaly = (mse > threshold).astype(int)\n",
    "    y_true_anomaly = (y_test != clean_idx).astype(int)\n",
    "    \n",
    "    ae_recall = recall_score(y_true_anomaly, y_pred_anomaly)\n",
    "    \n",
    "    return {\n",
    "        \"CNN Accuracy\": cnn_acc,\n",
    "        \"AE Recall\": ae_recall,\n",
    "        \"AE Threshold\": threshold\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Execute Comparison ---\n",
    "results = {}\n",
    "\n",
    "# Define the experiments\n",
    "experiments = {\n",
    "    \"Baseline (TopHat)\": filter_baseline_tophat,\n",
    "    \"No Filter (Raw)\": filter_none,\n",
    "    \"Gaussian Blur\": filter_gaussian\n",
    "}\n",
    "\n",
    "for exp_name, func in experiments.items():\n",
    "    results[exp_name] = run_experiment(exp_name, func)\n",
    "\n",
    "print(\"\\n--- FINAL RESULTS ---\")\n",
    "print(\"{:<20} | {:<15} | {:<15}\".format(\"Experiment\", \"CNN Accuracy\", \"AE Recall\"))\n",
    "print(\"-\"*56)\n",
    "for name, metrics in results.items():\n",
    "    print(\"{:<20} | {:.2f}%          | {:.2f}%\".format(\n",
    "        name, \n",
    "        metrics['CNN Accuracy']*100, \n",
    "        metrics['AE Recall']*100\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Visualization ---\n",
    "labels = list(results.keys())\n",
    "cnn_scores = [results[k]['CNN Accuracy'] for k in labels]\n",
    "ae_scores = [results[k]['AE Recall'] for k in labels]\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "rects1 = ax.bar(x - width/2, cnn_scores, width, label='CNN Accuracy')\n",
    "rects2 = ax.bar(x + width/2, ae_scores, width, label='AE Recall')\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Performance Comparison: Preprocessing Impact')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{:.1f}%'.format(height*100),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
